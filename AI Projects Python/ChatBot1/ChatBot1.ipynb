{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a054635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import nltk \n",
    "import string \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad9d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"chatbot corpus.txt\",'r',errors=\"ignore\")\n",
    "rawDoc = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29484e76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data science is an interdisciplinary academic field [1] that uses statistics, scientific computing, scientific methods, processes, algorithms and systems to extract or extrapolate knowledge and insights from noisy, structured, and unstructured data.[2]\\n\\nData science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).[3] Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.[4]\\n\\nData science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyse actual phenomena\" with data.[5] It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.[6] However, data science is different from computer science and information science. Turing Award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational, and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.[7][8]\\n\\nA data scientist is the professional who creates programming code and combines it with statistical knowledge to create insights from data.[9]\\n\\nFoundations\\nData science is an interdisciplinary field[10] focused on extracting knowledge from typically large data sets and applying the knowledge and insights from that data to solve problems in a wide range of application domains.[11] The field encompasses preparing data for analysis, formulating data science problems, analyzing data, developing data-driven solutions, and presenting findings to inform high-level decisions in a broad range of application domains. As such, it incorporates skills from computer science, statistics, information science, mathematics, data visualization, information visualization, data sonification, data integration, graphic design, complex systems, communication and business.[12][13] Statistician Nathan Yau, drawing on Ben Fry, also links data science to humanâ€“computer interaction: users should be able to intuitively control and explore data.[14][15] In 2015, the American Statistical Association identified database management, statistics and machine learning, and distributed and parallel systems as the three emerging foundational professional communities.[16]\\n\\nRelationship to statistics\\nMany statisticians, including Nate Silver, have argued that data science is not a new field, but rather another name for statistics.[17] Others argue that data science is distinct from statistics because it focuses on problems and techniques unique to digital data.[18] Vasant Dhar writes that statistics emphasizes quantitative data and description. In contrast, data science deals with quantitative and qualitative data (e.g. from images, text, sensors, transactions or customer information, etc) and emphasizes prediction and action.[19] Andrew Gelman of Columbia University has described statistics as a nonessential part of data science.[20]\\n\\nStanford professor David Donoho writes that data science is not distinguished from statistics by the size of datasets or use of computing and that many graduate programs misleadingly advertise their analytics and statistics training as the essence of a data-science program. He describes data science as an applied field growing out of traditional statistics.[21]\\n\\nEtymology\\nEarly usage\\nIn 1962, John Tukey described a field he called \"data analysis\", which resembles modern data science.[21] In 1985, in a lecture given to the Chinese Academy of Sciences in Beijing, C. F. Jeff Wu used the term \"data science\" for the first time as an alternative name for statistics.[22] Later, attendees at a 1992 statistics symposium at the University of Montpellier II acknowledged the emergence of a new discipline focused on data of various origins and forms, combining established concepts and principles of statistics and data analysis with computing.[23][24]\\n\\nThe term \"data science\" has been traced back to 1974, when Peter Naur proposed it as an alternative name for computer science.[6] In 1996, the International Federation of Classification Societies became the first conference to specifically feature data science as a topic.[6] However, the definition was still in flux. After the 1985 lecture at the Chinese Academy of Sciences in Beijing, in 1997 C. F. Jeff Wu again suggested that statistics should be renamed data science. He reasoned that a new name would help statistics shed inaccurate stereotypes, such as being synonymous with accounting or limited to describing data.[25] In 1998, Hayashi Chikio argued for data science as a new, interdisciplinary concept, with three aspects: data design, collection, and analysis.[24]\\n\\nDuring the 1990s, popular terms for the process of finding patterns in datasets (which were increasingly large) included \"knowledge discovery\" and \"data mining\".[6][26]\\n\\nModern usage\\nIn 2012, technologists Thomas H. Davenport and DJ Patil declared \"Data Scientist: The Sexiest Job of the 21st Century\",[27] a catch-phrase that was picked up even by major-city newspapers like the New York Times[28] and the Boston Globe.[29] A decade later, they reaffirmed it, stating \"the job is more in demand than ever with employers\".[30]\\n\\nThe modern conception of data science as an independent discipline is sometimes attributed to William S. Cleveland.[31] In a 2001 paper, he advocated an expansion of statistics beyond theory into technical areas; because this would significantly change the field, it warranted a new name.[26] \"Data science\" became more widely used in the next few years: in 2002, the Committee on Data for Science and Technology launched Data Science Journal. In 2003, Columbia University launched The Journal of Data Science.[26] In 2014, the American Statistical Association\\'s Section on Statistical Learning and Data Mining changed its name to the Section on Statistical Learning and Data Science, reflecting the ascendant popularity of data science.[32]\\n\\nThe professional title of \"data scientist\" has been attributed to DJ Patil and Jeff Hammerbacher in 2008.[33] Though it was used by the National Science Board in their 2005 report \"Long-Lived Digital Data Collections: Enabling Research and Education in the 21st Century\", it referred broadly to any key role in managing a digital data collection.[34]\\n\\nThere is still no consensus on the definition of data science, and it is considered by some to be a buzzword.[35] Big data is a related marketing term.[36] Data scientists are responsible for breaking down big data into usable information and creating software and algorithms that help companies and organizations determine optimal operations.[37]\\n\\nSee also\\nOpen Data Science Conference\\nScientific Data\\nWomen in Data\\nPython (programming language)\\nData engineering\\nBig data\\nMachine learning\\nReferences\\n Donoho, David (2017). \"50 Years of Data Science\". Journal of Computational and Graphical Statistics. 26 (4): 745â€“766. doi:10.1080/10618600.2017.1384734. S2CID 114558008.\\n Dhar, V. (2013). \"Data science and prediction\". Communications of the ACM. 56 (12): 64â€“73. doi:10.1145/2500499. S2CID 6107147. Archived from the original on 9 November 2014. Retrieved 2 September 2015.\\n Danyluk, A.; Leidig, P. (2021). Computing Competencies for Undergraduate Data Science Curricula (PDF). ACM Data Science Task Force Final Report (Report).\\n Mike, Koby and Hazzan, Orit. \"Why Is It Hard to Define Data Science?\". cacm.acm.org. Retrieved 3 January 2023.\\n Hayashi, Chikio (1 January 1998). \"What is Data Science? Fundamental Concepts and a Heuristic Example\". In Hayashi, Chikio; Yajima, Keiji; Bock, Hans-Hermann; Ohsumi, Noboru; Tanaka, Yutaka; Baba, Yasumasa (eds.). Data Science, Classification, and Related Methods. Studies in Classification, Data Analysis, and Knowledge Organization. Springer Japan. pp. 40â€“51. doi:10.1007/978-4-431-65950-1_3. ISBN 9784431702085.\\n Cao, Longbing (29 June 2017). \"Data Science: A Comprehensive Overview\". ACM Computing Surveys. 50 (3): 43:1â€“43:42. doi:10.1145/3076253. ISSN 0360-0300. S2CID 207595944.\\n Tony Hey; Stewart Tansley; Kristin Michele Tolle (2009). The Fourth Paradigm: Data-intensive Scientific Discovery. Microsoft Research. ISBN 978-0-9825442-0-4. Archived from the original on 20 March 2017.\\n Bell, G.; Hey, T.; Szalay, A. (2009). \"Computer Science: Beyond the Data Deluge\". Science. 323 (5919): 1297â€“1298. doi:10.1126/science.1170411. ISSN 0036-8075. PMID 19265007. S2CID 9743327.\\n Davenport, Thomas H.; Patil, D. J. (October 2012). \"Data Scientist: The Sexiest Job of the 21st Century\". Harvard Business Review. 90 (10): 70â€“76, 128. PMID 23074866. Retrieved 18 January 2016.\\n Emmert-Streib, Frank; Dehmer, Matthias (2018). \"Defining data science by a data-driven quantification of the community\". Machine Learning and Knowledge Extraction. 1: 235â€“251. doi:10.3390/make1010015.\\n \"About Data Science\". Data Science Association. Archived from the original on 10 August 2020. Retrieved 3 April 2020.\\n \"1. Introduction: What Is Data Science?\". Doing Data Science [Book]. Oâ€™Reilly. Retrieved 3 April 2020.\\n \"the three sexy skills of data geeks\". m.e.driscoll: data utopian. 27 May 2009. Retrieved 3 April 2020.\\n Yau, Nathan (4 June 2009). \"Rise of the Data Scientist\". FlowingData. Retrieved 3 April 2020.\\n \"Basic Example\". benfry.com. Retrieved 3 April 2020.\\n \"ASA Statement on the Role of Statistics in Data Science\". AmStatNews. American Statistical Association. 1 October 2015. Archived from the original on 20 June 2019. Retrieved 29 May 2019.\\n \"Nate Silver: What I need from statisticians\". Statistics Views. Retrieved 3 April 2020.\\n \"What\\'s the Difference Between Data Science and Statistics?\". Priceonomics. 13 October 2015. Retrieved 3 April 2020.\\n Vasant Dhar (1 December 2013). \"Data science and prediction\". Communications of the ACM. 56 (12): 64â€“73. doi:10.1145/2500499. S2CID 6107147.\\n \"Statistics is the least important part of data science Â« Statistical Modeling, Causal Inference, and Social Science\". statmodeling.stat.columbia.edu. Retrieved 3 April 2020.\\n Donoho, David (18 September 2015). \"50 years of Data Science\" (PDF). Retrieved 2 April 2020.\\n Wu, C. F. Jeff (1986). \"Future directions of statistical research in China: a historical perspective\" (PDF). Application of Statistics and Management. 1: 1â€“7. Retrieved 29 November 2020.\\n Escoufier, Yves; Hayashi, Chikio; Fichet, Bernard, eds. (1995). Data science and its applications. Tokyo: Academic Press/Harcourt Brace. ISBN 0-12-241770-4. OCLC 489990740.\\n Murtagh, Fionn; Devlin, Keith (2018). \"The Development of Data Science: Implications for Education, Employment, Research, and the Data Revolution for Sustainable Development\". Big Data and Cognitive Computing. 2 (2): 14. doi:10.3390/bdcc2020014.\\n Wu, C. F. Jeff. \"Statistics=Data Science?\" (PDF). Retrieved 2 April 2020.\\n Press, Gil. \"A Very Short History of Data Science\". Forbes. Retrieved 3 April 2020.\\n Davenport, Thomas (1 October 2012). \"Data Scientist: The Sexiest Job of the 21st Century\". Harvard Business Review. Retrieved 10 October 2022.\\n Miller, Claire (4 April 2013). \"Data Science: The Numbers of Our Lives\". New York Times. New York City. Retrieved 10 October 2022.\\n Borchers, Callum (11 November 2015). \"Behind the scenes of the \\'sexiest job of the 21st century\\'\". Boston Globe. Boston. Retrieved 10 October 2022.\\n Davenport, Thomas (15 July 2022). \"Is Data Scientist Still the Sexiest Job of the 21st Century?\". Harvard Business Review. Retrieved 10 October 2022.\\n Gupta, Shanti (11 December 2015). \"William S. Cleveland\". Retrieved 2 April 2020.\\n Talley, Jill (1 June 2016). \"ASA Expands Scope, Outreach to Foster Growth, Collaboration in Data Science\". Amstat News. American Statistical Association.\\n Davenport, Thomas H.; Patil, D. J. (1 October 2012). \"Data Scientist: The Sexiest Job of the 21st Century\". Harvard Business Review. No. October 2012. ISSN 0017-8012. Retrieved 3 April 2020.\\n \"US NSF â€“ NSB-05-40, Long-Lived Digital Data Collections Enabling Research and Education in the 21st Century\". www.nsf.gov. Retrieved 3 April 2020.\\n Press, Gil. \"Data Science: What\\'s The Half-Life of a Buzzword?\". Forbes. Retrieved 3 April 2020.\\n Pham, Peter. \"The Impacts of Big Data That You May Not Have Heard Of\". Forbes. Retrieved 3 April 2020.\\n Martin, Sophia (20 September 2019). \"How Data Science will Impact Future of Businesses?\". Medium. Retrieved 3 April 2020.\\nvte\\nData\\nAugmentationAnalysisArchaeologyBigCleansingCollectionCompressionCorruptionCurationDegradationEditingETL/ELT ExtractTransformLoadFarmingFormat managementFusionIntegrationIntegrityLibraryLineageLossManagementMigrationMiningPhilanthropyPre-processingPreservationProtection (privacy)PublishingRecoveryReductionRetentionQualityScienceScrapingScrubbingSecurityStewardshipStorageValidationWarehouseWrangling/munging\\nCategories: Information scienceComputer occupationsComputational fields of studyData analysis'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f851d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDocLower = rawDoc.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7bc264c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data science is an interdisciplinary academic field [1] that uses statistics, scientific computing, scientific methods, processes, algorithms and systems to extract or extrapolate knowledge and insights from noisy, structured, and unstructured data.[2]\\n\\ndata science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).[3] data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.[4]\\n\\ndata science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyse actual phenomena\" with data.[5] it uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.[6] however, data science is different from computer science and information science. turing award winner jim gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational, and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.[7][8]\\n\\na data scientist is the professional who creates programming code and combines it with statistical knowledge to create insights from data.[9]\\n\\nfoundations\\ndata science is an interdisciplinary field[10] focused on extracting knowledge from typically large data sets and applying the knowledge and insights from that data to solve problems in a wide range of application domains.[11] the field encompasses preparing data for analysis, formulating data science problems, analyzing data, developing data-driven solutions, and presenting findings to inform high-level decisions in a broad range of application domains. as such, it incorporates skills from computer science, statistics, information science, mathematics, data visualization, information visualization, data sonification, data integration, graphic design, complex systems, communication and business.[12][13] statistician nathan yau, drawing on ben fry, also links data science to humanâ€“computer interaction: users should be able to intuitively control and explore data.[14][15] in 2015, the american statistical association identified database management, statistics and machine learning, and distributed and parallel systems as the three emerging foundational professional communities.[16]\\n\\nrelationship to statistics\\nmany statisticians, including nate silver, have argued that data science is not a new field, but rather another name for statistics.[17] others argue that data science is distinct from statistics because it focuses on problems and techniques unique to digital data.[18] vasant dhar writes that statistics emphasizes quantitative data and description. in contrast, data science deals with quantitative and qualitative data (e.g. from images, text, sensors, transactions or customer information, etc) and emphasizes prediction and action.[19] andrew gelman of columbia university has described statistics as a nonessential part of data science.[20]\\n\\nstanford professor david donoho writes that data science is not distinguished from statistics by the size of datasets or use of computing and that many graduate programs misleadingly advertise their analytics and statistics training as the essence of a data-science program. he describes data science as an applied field growing out of traditional statistics.[21]\\n\\netymology\\nearly usage\\nin 1962, john tukey described a field he called \"data analysis\", which resembles modern data science.[21] in 1985, in a lecture given to the chinese academy of sciences in beijing, c. f. jeff wu used the term \"data science\" for the first time as an alternative name for statistics.[22] later, attendees at a 1992 statistics symposium at the university of montpellier ii acknowledged the emergence of a new discipline focused on data of various origins and forms, combining established concepts and principles of statistics and data analysis with computing.[23][24]\\n\\nthe term \"data science\" has been traced back to 1974, when peter naur proposed it as an alternative name for computer science.[6] in 1996, the international federation of classification societies became the first conference to specifically feature data science as a topic.[6] however, the definition was still in flux. after the 1985 lecture at the chinese academy of sciences in beijing, in 1997 c. f. jeff wu again suggested that statistics should be renamed data science. he reasoned that a new name would help statistics shed inaccurate stereotypes, such as being synonymous with accounting or limited to describing data.[25] in 1998, hayashi chikio argued for data science as a new, interdisciplinary concept, with three aspects: data design, collection, and analysis.[24]\\n\\nduring the 1990s, popular terms for the process of finding patterns in datasets (which were increasingly large) included \"knowledge discovery\" and \"data mining\".[6][26]\\n\\nmodern usage\\nin 2012, technologists thomas h. davenport and dj patil declared \"data scientist: the sexiest job of the 21st century\",[27] a catch-phrase that was picked up even by major-city newspapers like the new york times[28] and the boston globe.[29] a decade later, they reaffirmed it, stating \"the job is more in demand than ever with employers\".[30]\\n\\nthe modern conception of data science as an independent discipline is sometimes attributed to william s. cleveland.[31] in a 2001 paper, he advocated an expansion of statistics beyond theory into technical areas; because this would significantly change the field, it warranted a new name.[26] \"data science\" became more widely used in the next few years: in 2002, the committee on data for science and technology launched data science journal. in 2003, columbia university launched the journal of data science.[26] in 2014, the american statistical association\\'s section on statistical learning and data mining changed its name to the section on statistical learning and data science, reflecting the ascendant popularity of data science.[32]\\n\\nthe professional title of \"data scientist\" has been attributed to dj patil and jeff hammerbacher in 2008.[33] though it was used by the national science board in their 2005 report \"long-lived digital data collections: enabling research and education in the 21st century\", it referred broadly to any key role in managing a digital data collection.[34]\\n\\nthere is still no consensus on the definition of data science, and it is considered by some to be a buzzword.[35] big data is a related marketing term.[36] data scientists are responsible for breaking down big data into usable information and creating software and algorithms that help companies and organizations determine optimal operations.[37]\\n\\nsee also\\nopen data science conference\\nscientific data\\nwomen in data\\npython (programming language)\\ndata engineering\\nbig data\\nmachine learning\\nreferences\\n donoho, david (2017). \"50 years of data science\". journal of computational and graphical statistics. 26 (4): 745â€“766. doi:10.1080/10618600.2017.1384734. s2cid 114558008.\\n dhar, v. (2013). \"data science and prediction\". communications of the acm. 56 (12): 64â€“73. doi:10.1145/2500499. s2cid 6107147. archived from the original on 9 november 2014. retrieved 2 september 2015.\\n danyluk, a.; leidig, p. (2021). computing competencies for undergraduate data science curricula (pdf). acm data science task force final report (report).\\n mike, koby and hazzan, orit. \"why is it hard to define data science?\". cacm.acm.org. retrieved 3 january 2023.\\n hayashi, chikio (1 january 1998). \"what is data science? fundamental concepts and a heuristic example\". in hayashi, chikio; yajima, keiji; bock, hans-hermann; ohsumi, noboru; tanaka, yutaka; baba, yasumasa (eds.). data science, classification, and related methods. studies in classification, data analysis, and knowledge organization. springer japan. pp. 40â€“51. doi:10.1007/978-4-431-65950-1_3. isbn 9784431702085.\\n cao, longbing (29 june 2017). \"data science: a comprehensive overview\". acm computing surveys. 50 (3): 43:1â€“43:42. doi:10.1145/3076253. issn 0360-0300. s2cid 207595944.\\n tony hey; stewart tansley; kristin michele tolle (2009). the fourth paradigm: data-intensive scientific discovery. microsoft research. isbn 978-0-9825442-0-4. archived from the original on 20 march 2017.\\n bell, g.; hey, t.; szalay, a. (2009). \"computer science: beyond the data deluge\". science. 323 (5919): 1297â€“1298. doi:10.1126/science.1170411. issn 0036-8075. pmid 19265007. s2cid 9743327.\\n davenport, thomas h.; patil, d. j. (october 2012). \"data scientist: the sexiest job of the 21st century\". harvard business review. 90 (10): 70â€“76, 128. pmid 23074866. retrieved 18 january 2016.\\n emmert-streib, frank; dehmer, matthias (2018). \"defining data science by a data-driven quantification of the community\". machine learning and knowledge extraction. 1: 235â€“251. doi:10.3390/make1010015.\\n \"about data science\". data science association. archived from the original on 10 august 2020. retrieved 3 april 2020.\\n \"1. introduction: what is data science?\". doing data science [book]. oâ€™reilly. retrieved 3 april 2020.\\n \"the three sexy skills of data geeks\". m.e.driscoll: data utopian. 27 may 2009. retrieved 3 april 2020.\\n yau, nathan (4 june 2009). \"rise of the data scientist\". flowingdata. retrieved 3 april 2020.\\n \"basic example\". benfry.com. retrieved 3 april 2020.\\n \"asa statement on the role of statistics in data science\". amstatnews. american statistical association. 1 october 2015. archived from the original on 20 june 2019. retrieved 29 may 2019.\\n \"nate silver: what i need from statisticians\". statistics views. retrieved 3 april 2020.\\n \"what\\'s the difference between data science and statistics?\". priceonomics. 13 october 2015. retrieved 3 april 2020.\\n vasant dhar (1 december 2013). \"data science and prediction\". communications of the acm. 56 (12): 64â€“73. doi:10.1145/2500499. s2cid 6107147.\\n \"statistics is the least important part of data science â« statistical modeling, causal inference, and social science\". statmodeling.stat.columbia.edu. retrieved 3 april 2020.\\n donoho, david (18 september 2015). \"50 years of data science\" (pdf). retrieved 2 april 2020.\\n wu, c. f. jeff (1986). \"future directions of statistical research in china: a historical perspective\" (pdf). application of statistics and management. 1: 1â€“7. retrieved 29 november 2020.\\n escoufier, yves; hayashi, chikio; fichet, bernard, eds. (1995). data science and its applications. tokyo: academic press/harcourt brace. isbn 0-12-241770-4. oclc 489990740.\\n murtagh, fionn; devlin, keith (2018). \"the development of data science: implications for education, employment, research, and the data revolution for sustainable development\". big data and cognitive computing. 2 (2): 14. doi:10.3390/bdcc2020014.\\n wu, c. f. jeff. \"statistics=data science?\" (pdf). retrieved 2 april 2020.\\n press, gil. \"a very short history of data science\". forbes. retrieved 3 april 2020.\\n davenport, thomas (1 october 2012). \"data scientist: the sexiest job of the 21st century\". harvard business review. retrieved 10 october 2022.\\n miller, claire (4 april 2013). \"data science: the numbers of our lives\". new york times. new york city. retrieved 10 october 2022.\\n borchers, callum (11 november 2015). \"behind the scenes of the \\'sexiest job of the 21st century\\'\". boston globe. boston. retrieved 10 october 2022.\\n davenport, thomas (15 july 2022). \"is data scientist still the sexiest job of the 21st century?\". harvard business review. retrieved 10 october 2022.\\n gupta, shanti (11 december 2015). \"william s. cleveland\". retrieved 2 april 2020.\\n talley, jill (1 june 2016). \"asa expands scope, outreach to foster growth, collaboration in data science\". amstat news. american statistical association.\\n davenport, thomas h.; patil, d. j. (1 october 2012). \"data scientist: the sexiest job of the 21st century\". harvard business review. no. october 2012. issn 0017-8012. retrieved 3 april 2020.\\n \"us nsf â€“ nsb-05-40, long-lived digital data collections enabling research and education in the 21st century\". www.nsf.gov. retrieved 3 april 2020.\\n press, gil. \"data science: what\\'s the half-life of a buzzword?\". forbes. retrieved 3 april 2020.\\n pham, peter. \"the impacts of big data that you may not have heard of\". forbes. retrieved 3 april 2020.\\n martin, sophia (20 september 2019). \"how data science will impact future of businesses?\". medium. retrieved 3 april 2020.\\nvte\\ndata\\naugmentationanalysisarchaeologybigcleansingcollectioncompressioncorruptioncurationdegradationeditingetl/elt extracttransformloadfarmingformat managementfusionintegrationintegritylibrarylineagelossmanagementmigrationminingphilanthropypre-processingpreservationprotection (privacy)publishingrecoveryreductionretentionqualitysciencescrapingscrubbingsecuritystewardshipstoragevalidationwarehousewrangling/munging\\ncategories: information sciencecomputer occupationscomputational fields of studydata analysis'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDocLower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b69e738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Meer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Meer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "sentenceTokenized = nltk.sent_tokenize(rawDocLower)\n",
    "wordTokenized = nltk.word_tokenize(rawDocLower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2439b0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data science is an interdisciplinary academic field [1] that uses statistics, scientific computing, scientific methods, processes, algorithms and systems to extract or extrapolate knowledge and insights from noisy, structured, and unstructured data.',\n",
       " '[2]\\n\\ndata science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).',\n",
       " '[3] data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.',\n",
       " '[4]\\n\\ndata science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyse actual phenomena\" with data.',\n",
       " '[5] it uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceTokenized[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78de4af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2516"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordTokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3d4c711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentenceTokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cd44c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27954683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem_tokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d70d5336",
   "metadata": {},
   "outputs": [],
   "source": [
    "removePunctDict = dict((ord(punct), None) for punct in string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c86b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem_normalize(text):\n",
    "    return lem_tokens(nltk.word_tokenize(text.lower().translate(removePunctDict)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7491525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREET_INPUTS= (\"hello\", \"hi\", \"greetings\", \"sup\", \"Motherffucker\", \"I donot want to talk to you, now fuck off aaaa thuuuu\")\n",
    "GREET_RESPONSES = [\"hi\", \"hey\", \"nods\", \"hiThere Bandar\", \"I am glad to see you bitch\"]\n",
    "def greet(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREET_INPUTS:\n",
    "            return random.choice(GREET_RESPONSES)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abd4b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "364d71ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(userResponse):\n",
    "    robo1Response = \" \"\n",
    "    TFIDFVec = TfidfVectorizer(tokenizer=lem_normalize, stop_words=\"english\")\n",
    "    tfidf = TFIDFVec.fit_transform(sentenceTokenized)\n",
    "    vals = cosine_similarity(tfidf[-1],tfidf)\n",
    "    idx = vals.argsort()[0][-2]\n",
    "    flat= vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if req_tfidf == 0:\n",
    "        robo1Response = robo1Response + \"I am  sorry I donot understand you\"\n",
    "        return robo1Response\n",
    "    else:\n",
    "        robo1Response = robo1Response +sentenceTokenized[idx]\n",
    "        return robo1Response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "937d8556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT: My name is your khasam, Let's have a conversation! Also, if you want to exit anytime, just type Bye!\n",
      "hello\n",
      "BOT: FUCK OF BSDK, NAZAR MAT AEN AB, GAAND MAAR LON GA TERI\n",
      "bye\n",
      "BOT:"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Meer/nltk_data'\n    - 'C:\\\\Users\\\\Meer\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Meer\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Meer\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Meer\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4.zip/omw-1.4/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Meer/nltk_data'\n    - 'C:\\\\Users\\\\Meer\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Meer\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Meer\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Meer\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10000\\1165278102.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mfinal_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordTokenized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"BOT:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_response\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m                 \u001b[0msentenceTokenized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_response\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10000\\1921967799.py\u001b[0m in \u001b[0;36mresponse\u001b[1;34m(userResponse)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mrobo1Response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mTFIDFVec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlem_normalize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"english\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTFIDFVec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentenceTokenized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2075\u001b[0m         \"\"\"\n\u001b[0;32m   2076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2077\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2078\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2079\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m         \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1202\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10000\\1297225050.py\u001b[0m in \u001b[0;36mlem_normalize\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlem_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlem_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremovePunctDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10000\\1537285757.py\u001b[0m in \u001b[0;36mlem_tokens\u001b[1;34m(tokens)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlem_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10000\\1537285757.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlem_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlemma\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mword\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \"\"\"\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__reader_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;31m# This is where the magic happens!  Transform ourselves into\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, omw_reader)\u001b[0m\n\u001b[0;32m   1174\u001b[0m             )\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprovenances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0momw_prov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# A cache to store the wordnet data of multiple languages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36momw_prov\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m         \u001b[0mprovdict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m         \u001b[0mprovdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eng\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m         \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_omw_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfileid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[0mprov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlangfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Meer/nltk_data'\n    - 'C:\\\\Users\\\\Meer\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Meer\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Meer\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Meer\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "print(\"BOT: My name is your khasam, Let's have a conversation! Also, if you want to exit anytime, just type Bye!\")\n",
    "while(flag==True):\n",
    "    user_response= input()\n",
    "    user_response = user_response.lower()\n",
    "    if(user_response == \"bye\"):\n",
    "        if user_response == \"thanks\" or user_response == \"thank you\":\n",
    "            flag = False\n",
    "            print(\"BOT: you are welcome bsdk lun pey charh\")\n",
    "        else:\n",
    "            if greet(user_response)!=None:\n",
    "                    print(\"BOT:\" +greet(user_response))\n",
    "            else:\n",
    "                sentenceTokenized.append(user_response)\n",
    "                wordTokenized=wordTokenized+nltk.word_tokenize(user_response)\n",
    "                final_words = list(set(wordTokenized))\n",
    "                print(\"BOT:\", end=\"\")\n",
    "                print(response(user_response))\n",
    "                sentenceTokenized.remove(user_response)\n",
    "    else:\n",
    "        flag=flag\n",
    "        print(\"BOT: FUCK OF BSDK, NAZAR MAT AEN AB, GAAND MAAR LON GA TERI\")\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62111c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
